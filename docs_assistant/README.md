
# ğŸ¤– Asistente de IA para Langchain

Un asistente que utiliza la API de embeddings de OpenAI con el modelo `text-embedding-3-small` para la documentaciÃ³n local de archivos html sobre Langchain. Este proyecto emplea herramientas como **Pinecone** como Ã­ndice y lugar de almacenamiento, creando una base vectorial a partir de informaciÃ³n recolectada mediante web scraping y una interfaz desarrollada en **Streamlit**.

## ğŸš€ Clonar el repositorio
Puedes clonar el repositorio usando el siguiente enlace y cambiar a la rama `LAB5_DOC_ASSISTANT`:
```bash
git clone https://github.com/JosueSay/Selectivo_IA.git
git checkout LAB5_DOC_ASSISTANT
```

## âš™ï¸ ConfiguraciÃ³n de la base vectorial en Pinecone

1. Accede a tu cuenta de [Pinecone](https://www.pinecone.io/).
2. Crea un Ã­ndice:
    - **Nombre del Ãndice:** Especifica un nombre Ãºnico.
    - **DimensiÃ³n del Ãndice:** Selecciona la dimensiÃ³n usando `Setup by model` y escoge el modelo `text-embedding-3-small`.
    - **Proveedor de Nube:** Escoge **AWS** como proveedor.
        - **RegiÃ³n:** Selecciona la regiÃ³n, puede ser *us-east-1*, *us-west-2*, o *eu-west-1*.
    - **Crear el Ãndice:** Haz clic en "Crear".

## ğŸ“¦ Instalar dependencias
Ejecuta el siguiente comando para instalar las dependencias necesarias:
```bash
pip install -r requirements.txt
```

## ğŸŒ Crear variables de entorno
Crea un archivo `.env` y aÃ±ade lo siguiente:
```bash
OPENAI_API_KEY=         # Clave de OpenAI
PINECONE_API_KEY=       # Clave de Pinecone
INDEX_NAME=             # Nombre del Ã­ndice de la base vectorial en Pinecone
PINECONE_ENVIRONMENT=   # RegiÃ³n del Ã­ndice 
```

## ğŸ—‚ï¸ Archivos importantes

- **`.\backend\core_langchain_docs.py`**: Script encargado de hacer backend para realizar solicitudes a la API de OpenAI usando el embebido `text-embedding-3-small`.
  
- **`.\frontend\app_docs.py`**: Script encargado de montar el frontend usando Streamlit.
  
- **`.\ingestions\ingestion.py`**: Script encargado de hacer la ingestion de data al indice de la base vectorial en Pinecone.

## â–¶ï¸ Ejecutar el cÃ³digo

1. Primero, ejecuta el script para el llenar la base vectorial con la data de los archivos html en `data/langchain-docs`:
   ```bash
   python .\ingestions\ingestion.py
   ```

2. Luego, ejecuta el script para la interfaz:
   ```bash
   streamlit run .\frontend\app_docs.py
   ```

Â¡Ingresa tu prompt para probar el chat! ğŸ’¬

## ğŸ’¡Promps Recomendados
1. **Â¿CuÃ¡l es el rol de Moira en Overwatch?**
2. **Â¿CuÃ¡les son las habilidades de Moira?**
3. **Â¿Tiene Moira algÃºn nombre adicional o alias?**
4. **Â¿CuÃ¡l es la misiÃ³n o meta de Moira dentro del universo de Overwatch?**
5. **Â¿CuÃ¡l es la historia de origen de Moira?**

## ğŸ¥ Video del funcionamiento
Puedes ver el video del funcionamiento en el siguiente enlace: [Video de funcionamiento](https://youtu.be/55dGOiw7cbI?si=gf0IQJ3UD7SaeaOB)
